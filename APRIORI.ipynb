{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: C:\\Users\\plee\\Desktop\\ALL\\DATA SCIENCE PROJECTS\n",
      "1. APRIORI.ipynb\n",
      "2. KMEANS.ipynb\n",
      "3. results.txt\n",
      "4. Teaching Hospital supporters.txt\n",
      "5. test.xlsx\n"
     ]
    }
   ],
   "source": [
    "#Import packages and print working directory\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import operator\n",
    "import pandas as pd1\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "#cleans the dataframe given the max num records, and what's the allowable cuttoff count for num rows\n",
    "def df_clean(dataframe, max_records, cutoff_count):\n",
    "    df = dataframe\n",
    "    df.columns = df.columns.str.upper()\n",
    "    cols = df.columns\n",
    "    cols_we_want = []\n",
    "    \n",
    "    for col in cols:\n",
    "        u_list = len(list(df[col].value_counts()))\n",
    "        num_list = df[col].count()\n",
    "        if(u_list > 1 and u_list != max_records and num_list > cutoff_count):\n",
    "            cols_we_want.append(col)\n",
    "    \n",
    "    return dataframe[cols_we_want]\n",
    "\n",
    "\n",
    "#Printing out simple statistc sof the data such as size and shape.\n",
    "def df_info(dataframe):\n",
    "    dataframe_size = dataframe.size\n",
    "    dataframe_rows, dataframe_cols = dataframe.shape\n",
    "    print(\"The size of the DF is\",dataframe_size,\".\")\n",
    "    print(\"The dimensions of the DF is\",dataframe_rows,\"rows and\",dataframe_cols,\"columns.\")\n",
    "    return\n",
    "    \n",
    "    \n",
    "#More insight of the columsn in the dataframe such as what type the column is, the unique count, index number,\n",
    "#name, and how many non-null elements are in the column\n",
    "def df_info_list(dataframe):\n",
    "    column_names = dataframe.columns\n",
    "    index = 0\n",
    "    for col in column_names:\n",
    "        unique_list_len = str(len(list((dataframe[col].value_counts()))))\n",
    "        print(str(index).ljust(5),unique_list_len.ljust(10),col.ljust(64),str(dataframe[col].count()).ljust(6),dataframe.dtypes[col])\n",
    "\n",
    "        index+=1\n",
    "    \n",
    "    \n",
    "#Return the column names of the given dataframe  \n",
    "def dfcol(dataframe):\n",
    "    return dataframe.columns\n",
    "\n",
    "\n",
    "#Print the current working directory\n",
    "def print_cwd():\n",
    "    print(\"Current working directory: \" + os.getcwd())\n",
    "    \n",
    "    files = [f for f in os.listdir(\".\") if os.path.isfile(f)]\n",
    "    count = 1\n",
    "    \n",
    "    for file in files:\n",
    "        print(str(count) +  \". \" + file)\n",
    "        count+=1\n",
    "    return\n",
    "\n",
    "#lower the name of the columns  \n",
    "def col_lower(dataframe):\n",
    "    dataframe.columns = [col.lower() for col in dataframe.columns]\n",
    "\n",
    "#replace the columns with all lowercase \n",
    "def replacer(dataframe,replace_this,replacement):\n",
    "    return dataframe.replace({replace_this:replacement},regex=True)\n",
    "\n",
    "\n",
    "\n",
    "#Grab value counts given the dataframe and the column\n",
    "def vcnt(dataframe, col):\n",
    "    return dataframe[col].value_counts()\n",
    "\n",
    "#Grab random hex color\n",
    "def randhex():\n",
    "   return \"#\" + ''.join([random.choice('0123456789ABCDEF') for x in range(6)])\n",
    "\n",
    "#Create a pie chart\n",
    "def create_pie(labels,data,title):\n",
    "    size = len(data)\n",
    "    colors = []\n",
    "\n",
    "    \n",
    "    def make_autopct(values):\n",
    "        def my_autopct(pct):\n",
    "            total = sum(values)\n",
    "            val = int(round(pct*total/100.0))\n",
    "            return '{p:.2f}%  ({v:d})'.format(p=pct,v=val)\n",
    "        return my_autopct\n",
    "    \n",
    "    for x in range(size):\n",
    "        colors.append(randhex())\n",
    "    plt.pie(\n",
    "        data,\n",
    "        labels=labels,\n",
    "        colors=colors,\n",
    "        shadow=True,\n",
    "        startangle=0,\n",
    "        autopct=make_autopct(data),\n",
    "        \n",
    "    )\n",
    "    \n",
    "    plt.title(title, bbox={'facecolor':'0.8', 'pad':5},y=1.08)\n",
    "    plt.axis('equal')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "print_cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read in the file and put it into a dataframe\n",
    "df = pd.read_excel(\"./test.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = df[['tch_id_and_name','amog_id_and_name']]\n",
    "l1 = df2['tch_id_and_name'].tolist()\n",
    "l2 = df2['amog_id_and_name'].tolist()\n",
    "l3 = []\n",
    "\n",
    "\n",
    "for ind,row in enumerate(l1):\n",
    "    l3.append([l1[ind],l2[ind]])\n",
    "\n",
    "    \n",
    "conns = []\n",
    "hos_lis = df2['tch_id_and_name'].drop_duplicates()\n",
    "\n",
    "hos_list = hos_lis.tolist()\n",
    "\n",
    "\n",
    "for hos in hos_lis:\n",
    "    main_list = []\n",
    "    for row in l3:\n",
    "        if(row[0] == hos):\n",
    "            main_list.append(row[1])\n",
    "    conns.append(main_list)\n",
    "\n",
    "\n",
    "    \n",
    "#with open('conns.txt','w+') as wr:\n",
    "#    index = 0\n",
    "#    for row in conns:\n",
    "#        wr.write(hos_list[index] + \": \" + str(row) + \"\\n\")\n",
    "#        index+=1\n",
    "#        \n",
    "#    wr.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Conduct the Apriori Algorihm, and format the results in a human readable way. \n",
    "\n",
    "from apyori import apriori\n",
    "results = list(apriori(conns,min_support=0.05))\n",
    "\n",
    "\n",
    "with open(\"results.txt\",\"w+\") as f:\n",
    "    for row in results:\n",
    "        mod2 = str(row)\n",
    "        mod2 = mod2.replace(\"RelationRecord\",\"\")\n",
    "        mod2 = mod2.replace(\"items_base=frozenset\",\"Subset\")\n",
    "        mod2 = mod2.replace(\"confidence=\",\"\\n\\tconfidence = \")\n",
    "        mod2 = mod2.replace(\"lift=\",\"\\n\\tlift = \")\n",
    "        mod2 = mod2.replace(\"items_add=frozenset\",\"\\nCompany: \")\n",
    "        mod2 = mod2.replace(\"items=frozenset\",\"Applicable Manufacturer or Applicable GPO Making Payment: \")\n",
    "        mod2 = mod2.replace(\"support=\",\"\\nsupport=\")\n",
    "        mod2 = mod2.replace(\"ordered_statistics=[\",\"\")\n",
    "        mod2 = mod2.replace(\"OrderedStatistic\", \"\\n\")\n",
    "        mod2 = mod2.replace(\"items_add\",\"\\nitems_add\")\n",
    "        mod2 = mod2[1:len(mod2)-2]\n",
    "        f.write(mod2 + \"\\n\\n\")\n",
    "    \n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
